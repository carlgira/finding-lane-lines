{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND LANE LINES\n",
    "\n",
    "Next, is all the algorithm that i wrote to find lane lines from the image and test videos. \n",
    "\n",
    "\n",
    "## Helper Functions\n",
    "This section includes the imports and some helper functions copied from the project template.\n",
    "    1. Canny Edges\n",
    "    2. Gaussian Blur\n",
    "    3. Region of interest\n",
    "    4. Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "\t\"\"\"Applies the Canny transform\"\"\"\n",
    "\treturn cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "\t\"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "\treturn cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "\t\"\"\" Applies an image mask to keep the region of the image defined\n",
    "\tby the polygon formed from `vertices`. The rest of the image is set to black.\n",
    "\t\"\"\"\n",
    "\tmask = np.zeros_like(img)\n",
    "\n",
    "\tif len(img.shape) > 2:\n",
    "\t\tchannel_count = img.shape[2]\n",
    "\t\tignore_mask_color = (255,) * channel_count\n",
    "\telse:\n",
    "\t\tignore_mask_color = 255\n",
    "\n",
    "\tcv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "\tmasked_image = cv2.bitwise_and(img, mask)\n",
    "\treturn masked_image\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_length, max_line_gap):\n",
    "\t\"\"\" Returns an image with hough lines drawn.\"\"\"\n",
    "\n",
    "\tlines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\tline_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\tdraw_lines(line_img, lines, thickness=15)\n",
    "\n",
    "\treturn line_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Selection and image transformation\n",
    "\n",
    "Transform the image to __HSL color space__ using the function __cv2.cvtColor__ (after doing this transformation the  lane lines can be seeing more clearly)\n",
    "\n",
    "Create a mask to select the yellow and white colors using the function __cv2.inRange__, filtering just the wanted colors and reducing the objects to be evaluated in the region of interest.\n",
    "\n",
    "Got the ideas for color selection and image transformation from https://github.com/naokishibuya/car-finding-lane-lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hls(image):\n",
    "\t\"\"\"Convert an image to HSL color space\"\"\"\n",
    "\treturn cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "\n",
    "def select_white_yellow(image):\n",
    "\t\"\"\"Create a mask to select white and yellow colors\"\"\"\n",
    "\tconverted = convert_hls(image)\n",
    "\t# white color mask\n",
    "\tlower = np.uint8([0, 200,   0])\n",
    "\tupper = np.uint8([255, 255, 255])\n",
    "\twhite_mask = cv2.inRange(converted, lower, upper)\n",
    "\t# yellow color mask\n",
    "\tlower = np.uint8([10, 0, 100])\n",
    "\tupper = np.uint8([40, 255, 255])\n",
    "\tyellow_mask = cv2.inRange(converted, lower, upper)\n",
    "\t# combine the mask\n",
    "\tmask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\treturn cv2.bitwise_and(image, image, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and draw lane lines\n",
    "\n",
    "- Separate the lines divindig the image by half.\n",
    "- Use a linear regression to find left and right slope and intercept.\n",
    "- Use the slope and intercept to draw the lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(img, color, thickness, y1, y2, slope, intercept):\n",
    "\t\"\"\" Function to calculate and draw line based on slope and intercept\"\"\"\n",
    "\tx1 = int((y1 - intercept)/slope)\n",
    "\tx2 = int((y2 - intercept)/slope)\n",
    "\tcv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "\t\"\"\"Function to draw the lane lines.\n",
    "\n",
    "\t1. Separate the lines between the right and left side\n",
    "\t2. Use linear regression models to calculate slope and intercept of each lane\n",
    "\t3. Calculate coordinates of the lane using the slope and intercept\n",
    "\t4. Draw lane line over image\n",
    "\t\"\"\"\n",
    "\timshape = img.shape\n",
    "\n",
    "\t# Divide the points between left and right side\n",
    "\tleft_lines = lines[lines[:, :, 0] < imshape[1]/2]\n",
    "\tright_lines = lines[lines[:, :, 0] > imshape[1]/2]\n",
    "\n",
    "\t# Use a linear regression to get the slope and intercept of left lane line\n",
    "\tleft_regr = linear_model.LinearRegression()\n",
    "\tleft_regr.fit(np.reshape(left_lines[:, [0, 2]], (-1, 1)), np.reshape(left_lines[:, [1, 3]], (-1, 1)))\n",
    "\n",
    "\t# Use a linear regression to get the slope and intercept of right lane line\n",
    "\tright_regr = linear_model.LinearRegression()\n",
    "\tright_regr.fit(np.reshape(right_lines[:, [0, 2]], (-1, 1)), np.reshape(right_lines[:, [1, 3]], (-1, 1)))\n",
    "\n",
    "\t# Draw right lane\n",
    "\tif len(right_lines) > 0:\n",
    "\t\tdraw_line(img, color, thickness,  imshape[0], int(imshape[0]*5/8), right_regr.coef_, right_regr.intercept_)\n",
    "\n",
    "\t# Draw left lane\n",
    "\tif len(left_lines) > 0:\n",
    "\t\tdraw_line(img, color, thickness, imshape[0], int(imshape[0]*5/8), left_regr.coef_, left_regr.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Image and Video\n",
    "The main algorithm join all the previous steps to read, filter, calculate and draw the lane lines.\n",
    "\n",
    "### Process Image\n",
    "These are the steps for the image process function\n",
    "\t1. Filter colors white and yellow on a HSL color space transformed image.\n",
    "\t2. Smooth edges with gaussian blur\n",
    "\t3. Canny edge detection\n",
    "\t4. Create a region of interest using polygon\n",
    "\t5. Get lane lines\n",
    "\t\t5.1 Hough Line Detection\n",
    "\t\t5.2 Separate points between left and right sides\n",
    "\t\t5.3 Use regression models to calculate slope and intercept of left and right lanes\n",
    "\t6. Draw lane line with transparency\n",
    "    \n",
    "### Process Video\n",
    "Function to process the videos using the process_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "\t\"\"\"Main function to process image and draw lane lines\"\"\"\n",
    "\timshape = image.shape\n",
    "\n",
    "\t# Filter white and yellow color\n",
    "\tfilter_img = select_white_yellow(image)\n",
    "\n",
    "\t# Smooth edges with gaussian blur\n",
    "\tblur_img = gaussian_blur(filter_img, kernel_size=9)\n",
    "\n",
    "\t# Canny edges detection\n",
    "\tedges = canny(blur_img, low_threshold=50, high_threshold=100)\n",
    "\n",
    "\t# Create region of interest\n",
    "\tvertices = np.array([[(60, imshape[0]), (imshape[1]*7/16, imshape[0]*5/8), (imshape[1]*9/16, int(imshape[0]*5/8)), (imshape[1]-60, imshape[0])]], dtype=np.int32)\n",
    "\tmasked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "\t# Get lane lines\n",
    "\tline_img = hough_lines(masked_edges, rho=1, theta=np.pi/180, threshold=1, min_line_length=8, max_line_gap=1)\n",
    "\n",
    "\t# Draw lane lines on image with transparency\n",
    "\tcopy_image = np.copy(image)\n",
    "\tlines_edges = cv2.addWeighted(copy_image, 0.8, line_img, 1, 0)\n",
    "\n",
    "\treturn lines_edges\n",
    "\n",
    "\n",
    "def process_video(video, video_output):\n",
    "\t\"\"\" Process frames of video using the process image function to draw lane lines\"\"\"\n",
    "\tclip1 = VideoFileClip(video)\n",
    "\tclip = clip1.fl_image(process_image)\n",
    "\tclip.write_videofile(video_output, audio=False, verbose=False, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save all images\n",
    "mpimg.imsave('output/solidWhiteCurve.jpg', process_image(mpimg.imread('test_images/solidWhiteCurve.jpg')))\n",
    "mpimg.imsave('output/solidWhiteRight.jpg', process_image(mpimg.imread('test_images/solidWhiteRight.jpg')))\n",
    "mpimg.imsave('output/solidYellowCurve.jpg', process_image(mpimg.imread('test_images/solidYellowCurve.jpg')))\n",
    "mpimg.imsave('output/solidYellowCurve2.jpg', process_image(mpimg.imread('test_images/solidYellowCurve2.jpg')))\n",
    "mpimg.imsave('output/solidYellowLeft.jpg', process_image(mpimg.imread('test_images/solidYellowLeft.jpg')))\n",
    "mpimg.imsave('output/whiteCarLaneSwitch.jpg', process_image(mpimg.imread('test_images/whiteCarLaneSwitch.jpg')))\n",
    "\n",
    "# Process and save all videos\n",
    "process_video(\"test_videos/solidWhiteRight.mp4\", 'output/solidWhiteRight.mp4')\n",
    "process_video(\"test_videos/solidYellowLeft.mp4\", 'output/solidYellowLeft.mp4')\n",
    "process_video(\"test_videos/challenge.mp4\", 'output/challenge.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "\n",
    "|                                                          |                                                   |\n",
    "|-----------------------------------------------------------|----------------------------------------------------|\n",
    "|<img src=\"output/solidWhiteCurve.jpg\",width=400,height=200>|<img src=\"output/solidWhiteRight.jpg\",width=400,height=200>|\n",
    "|output/solidWhiteCurve.jpg|output/solidWhiteRight.jpg|\n",
    "|<img src=\"output/solidYellowCurve.jpg\",width=400,height=200>|<img src=\"output/solidYellowCurve2.jpg\",width=400,height=200>|\n",
    "|output/solidYellowCurve.jpg|output/solidYellowCurve2.jpg|\n",
    "|<img src=\"output/solidYellowLeft.jpg\",width=400,height=200>|<img src=\"output/whiteCarLaneSwitch.jpg\",width=400,height=200>|\n",
    "|output/solidYellowLeft.jpg|output/whiteCarLaneSwitch.jpg|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "\n",
    "| |\n",
    "|-|\n",
    "|<video controls src=\"output/solidWhiteRight.mp4\",width=400,height=200/>|\n",
    "|output/solidWhiteRight.mp4|\n",
    "|<video controls src=\"output/solidYellowLeft.mp4\",width=400,height=200 />|\n",
    "|output/solidYellowLeft.mp4|\n",
    "\n",
    "\n",
    "## Challenge Video\n",
    "\n",
    "||\n",
    "|-|\n",
    "|<video controls src=\"output/challenge.mp4\",width=400,height=200/>|\n",
    "|output/challenge.mp4|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
